{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480cc0cb-59e3-4648-9968-53cdea747098",
   "metadata": {},
   "source": [
    "# Task 2: Populating Company Presence on the Internet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c1be1-598d-43dc-8b01-99d7563a00c2",
   "metadata": {},
   "source": [
    "BeautifulSoup and requests can only scrape static websites, but they cannot scrape the dynamic website that uses JS.\n",
    "Dynamically loading the content using JS is also known as AJAX(Asynchronous JavaScript and XML)\n",
    "\n",
    "Parsing-converting a string representation of a Python object into an actual object.\n",
    "Rendering- interpreting HTML, CSS, JS, and images into something that we see in a browser.\n",
    "\n",
    " (a way to deal with pagination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b59c2-997c-4a40-883d-0b64522b1738",
   "metadata": {},
   "source": [
    "Basic steps to perform this task:\n",
    "1. Connect to the MySQL database and extract company English names from the company_master table.\n",
    "2. Use these names to search on Google and extract the top 10 links for each company.\n",
    "3. Send an initial request to get the first page of search results.\n",
    "4. Extract links from the first page.\n",
    "5. Find the link to the next page and send a request to it if more results are needed.\n",
    "6. Repeat the process until you have collected the desired number of links (10 in this case).\n",
    "7. Update the `COMPANY_MASTER` table with the gathered links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a313dc7-1503-4c64-b131-98e96e7df8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb1369c-71d4-4447-9dc1-e8ebe7030c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Links:\n",
      "1: https://f1soft.com/\n",
      "2: https://np.linkedin.com/company/f1softgroup\n",
      "3: https://www.facebook.com/f1soft/\n",
      "4: https://twitter.com/f1soft\n",
      "5: https://play.google.com/store/apps/developer?id=F1soft&hl=en_US\n",
      "6: https://merojob.com/employer/f1soft-international/\n",
      "7: https://np.linkedin.com/in/sharmasubash\n",
      "8: https://np.linkedin.com/in/sharmasubash\n",
      "9: https://www.jobejee.com/employer/F1soft-International-/2280\n",
      "10: https://www.talentconnects.com.np/f1soft-international-29/career\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_google_search_results(query, num_results=10):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "                      '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    base_url = 'https://google.com'\n",
    "    search_url = f'{base_url}/search?q={query}'\n",
    "    links = []\n",
    "\n",
    "    while len(links) < num_results:\n",
    "        try:\n",
    "            response = requests.get(search_url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Find all <h3> tags in the current page of search results\n",
    "            for heading in soup.find_all('h3'):\n",
    "                parent_tag = heading.find_parent('a')\n",
    "                if parent_tag and 'href' in parent_tag.attrs:\n",
    "                    link = parent_tag['href'].strip()\n",
    "                    if re.match(r'^https?://(?!www\\.google\\.).+', link):\n",
    "                        links.append(link)\n",
    "                        if len(links) >= num_results:\n",
    "                            break\n",
    "\n",
    "            # Find the link to the next page\n",
    "            next_page = soup.select_one('a[id=\"pnnext\"]')\n",
    "            if next_page and next_page['href']:\n",
    "                search_url = base_url + next_page['href']\n",
    "            else:\n",
    "                break  # No more pages\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching URL: {e}\")\n",
    "            break\n",
    "\n",
    "    return links[:num_results]\n",
    "\n",
    "text = \"f1soft\"\n",
    "top_links = get_google_search_results(text, num_results=10)\n",
    "\n",
    "print(\"Top 10 Links:\")\n",
    "for i, link in enumerate(top_links, 1):\n",
    "    print(f\"{i}: {link}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e271c-9bf4-46d7-9d6a-88bf36e5680b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba3dec4-9cfa-4763-87cf-108a62b2ff83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
